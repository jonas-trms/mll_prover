\documentclass{beamer}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{amsmath,amsthm}
\usepackage{amssymb,cmll}
\usepackage{ebproof}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{trees}
\usepackage{bm}
\usepackage{algorithm}
\floatname{algorithm}{Algorithme}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{authblk}
\usepackage[backend=biber,style=alphabetic,sorting=ynt]{biblatex}
\usepackage[export]{adjustbox}
\usepackage[dvipsnames]{xcolor}

% dessins arbres : tikz
\tikzset{baseline=(current bounding box.center)}
\tikzset{level distance=1.3cm}

%imported from click and collect
\newcommand*{\orth}{^\perp}
\newcommand*{\tensor}{\otimes}

\newcommand*{\namedproofv}[2]{\hypo{#1}\infer[no rule]{1}{\vdash #2}}
\newcommand*{\hypv}[1]{\hypo{\vdash #1}}
\newcommand*{\axv}[1]{\infer{0}[\ensuremath{\mathit{ax}}]{\vdash #1}}
\newcommand*{\cutv}[1]{\infer{2}[\ensuremath{\mathit{cut}}]{\vdash #1}}
\newcommand*{\onev}[1]{\infer{0}[\ensuremath{\one}]{\vdash #1}}
\newcommand*{\botv}[1]{\infer{1}[\ensuremath{\bot}]{\vdash #1}}
\newcommand*{\topv}[1]{\infer{0}[\ensuremath{\top}]{\vdash #1}}
\newcommand*{\tensorv}[1]{\infer{2}[\ensuremath{\tensor}]{\vdash #1}}
\newcommand*{\parrv}[1]{\infer{1}[\ensuremath{\parr}]{\vdash #1}}
\newcommand*{\permv}[2]{\infer{1}[\ensuremath{\textit{ex}_{#1}}]{\vdash #2}}
\newcommand*{\withv}[1]{\infer{2}[\ensuremath{\with}]{\vdash #1}}
\newcommand*{\pluslv}[1]{\infer{1}[\ensuremath{\plus_1}]{\vdash #1}}
\newcommand*{\plusrv}[1]{\infer{1}[\ensuremath{\plus_2}]{\vdash #1}}
\newcommand*{\ocv}[1]{\infer{1}[\ensuremath{\oc}]{\vdash #1}}
\newcommand*{\wkv}[1]{\infer{1}[\ensuremath{?\mathit{w}}]{\vdash #1}}
\newcommand*{\cov}[1]{\infer{1}[\ensuremath{?\mathit{c}}]{\vdash #1}}
\newcommand*{\dev}[1]{\infer{1}[\ensuremath{?\mathit{d}}]{\vdash #1}}
\newcommand*{\defv}[1]{\infer[dashed]{1}[\ensuremath{\mathit{def}}]{\vdash #1}}
\newcommand*{\permapp}[2]{#2 #1}
\newcommand*{\someperm}{\varsigma}
\newcommand*{\someadd}{\rho}
\newcommand*{\someaddbis}{w}
\newcommand*{\someproof}{\pi}
\newcommand*{\sequent}{\Gamma}
\newcommand*{\sequentbis}{\Delta}
\newcommand*{\size}[1]{\mathopen{|}#1\mathclose{|}}

\newcommand*{\Left}{\textnormal{\texttt{L}}}
\newcommand*{\Right}{\textnormal{\texttt{R}}}

\newcommand*{\proofs}{\ensuremath{\mathcal{P}}}
\newcommand*{\sequents}{\ensuremath{\mathcal{S}}}
\newcommand*{\addresses}{\ensuremath{\mathcal{A}}}
\newcommand*{\treeaddresses}{\ensuremath{\mathcal{A'}}}
\newcommand*{\trees}{\ensuremath{\mathcal{T}}}
\newcommand*{\treespartial}{\ensuremath{\mathcal{T'}}}
\newcommand*{\representationslarge}{\ensuremath{\trees \times \sequents}}
\newcommand*{\representations}{\ensuremath{\mathcal{R}}}
\newcommand*{\representationspartiallarge}{\ensuremath{\treespartial \times \sequents}}
\newcommand*{\representationspartial}{\ensuremath{\mathcal{R'}}}
\newcommand*{\setshuffle}{\bowtie}

\newcommand*{\encode}{\ensuremath{\varphi}}
\newcommand*{\decode}{\ensuremath{\gamma}}

\newcommand*{\height}{\ensuremath{h}}
\newcommand*{\relapprox}{\ensuremath{\triangleleft}}
\newcommand*{\relapproxlarge}{\ensuremath{\relapprox^*}}
\newcommand*{\unknown}{H}

\newcommand*{\lowapprox}{\ensuremath{\Sigma_0}}
\newcommand*{\lowapproxspec}{\ensuremath{\Sigma'_0}}
\newcommand*{\highapprox}{\ensuremath{\Sigma_1}}
\newcommand*{\highapproxspec}{\ensuremath{\Sigma'_1}}

\newcommand*{\foblig}[1]{\textcolor{red}{#1}}

\newcommand*{\treesimplify}{\ensuremath{s}}

\newcommand*{\caddpartial}{(a)}
\newcommand*{\clinpartial}{(b')}
\newcommand*{\cdespartial}{(c)}

\newcommand*{\exactcond}{\bigstar_1}
\newcommand*{\exactcondbis}{\bigstar_2}

\title{Conception et implémentation d'un assistant de preuve pour le fragment multiplicatif de la logique linéaire}
\author{Jonas Torriero-Meskour}
\institute{ENS de Lyon, stage de L3 au LIP encadré par Olivier Laurent}
\date{4 juin 2024 -- 19 juillet 2024}

\addtobeamertemplate{navigation symbols}{}{ \hspace{1em}    \usebeamerfont{footline}%
    \insertframenumber / \inserttotalframenumber }

\begin{document}

\begin{frame}
   \titlepage
\end{frame}

\begin{frame}{Plan général}
    \begin{itemize}
        \item Introduction \& objectif du stage
        \item Présentation de la logique linéaire
        \item Principe général de l'assistant de preuve
        \item Quelques résultats de fiabilité
        \item Conclusion
    \end{itemize}
\end{frame}

\begin{frame}{Introduction}
    \begin{itemize}
        \item Logique linéaire: introduite en 1987 par Jean-Yves Girard.
            \pause
        \item On s'intéresse au fragment multiplicatif MLL.
            \pause
        \item Intérêt: voir les hypothèses comme des ressources.
            \pause
        \item Nombreuses applications en informatique: programmation fonctionnelle, théorie de la preuve...
            \pause
        \item D'où une nécessité... écrire facilement des preuves!
    \end{itemize}    
\end{frame}

\begin{frame}{Problématique}
    \begin{itemize}
        \item Plusieurs syntaxes possibles, dont... le calcul des séquents!
        \item Notre objectif: concevoir un assitant de preuve interactif pour le calcul des séquents, guidant l'utilisateur efficacement et pas à pas.
    \end{itemize}
\end{frame}

\begin{frame}{Un prédecesseur}
    \centering
    \includegraphics[scale=0.35]{images/C&C_home.png}

    \pause
    
    \begin{itemize}
        \item L'une des premières interfaces graphiques pour le calcul des séquents linéaire.
            \pause
        \item Cependant... but pédagogique, s'adresse à des débutants.
            \pause
        \item Problème: inadapté à utilisateur expert, l'information demandée est redondante.
    \end{itemize}

%%démo? ou après "La structure des preuves est redondante"

\end{frame}

\begin{frame}{Objectif du stage}
    \begin{itemize}
        \item Concevoir un outil minimisant l'information requise.
        \item Notre contribution:
            \begin{itemize}
                \item Concevoir un formalisme du calcul des séquents adapté.
                
                \item Implémenter une interface interactive, automatisant certaines étapes.
            \end{itemize}
            \pause
        \item Résultat: mll\_prover, implémenté en OCaml !
    \end{itemize}
\end{frame}

\begin{frame}{Séquents en logique linéaire}
    \begin{itemize}
        \item Formules: $F := X \mid X\orth \mid F \parr F \mid F \tensor F$.
            \pause
        \item Intuition: $\orth \sim \neg$, $\parr \sim \lor$, $\tensor \sim \land$.
            \pause
        \item Remarque: on ne peut nier que les atomes.
            \pause \\ 
        \item Les séquents sont des formes disjonctives unilatérales: en logique classique, \\ $A \vdash B$ $\; \sim \; \; \vdash A \implies B$ $\; \sim \; \; \vdash \neg A \lor B$ $\; \sim \; \; \vdash \neg A, B$.\\         \pause
        \item Séquent: liste de formules. Un séquent est intuitivement une disjonction: $\vdash X_1, X_2, X_3$ $\sim \; \vdash X_1 \lor X_2 \lor X_3$. 
        \pause\\
        $\rightarrow$ En logique linéaire: $\vdash A\orth{}, B$.
    \end{itemize}
\end{frame}

\begin{frame}{Quelques exemples de séquents}
    \begin{itemize}
        \item $F := X \mid X\orth \mid F \parr F \mid F \tensor F$.\\
        $\orth \sim \neg$, $\parr \sim \lor$, $\tensor \sim \land$.\\
        Séquent: liste de formules (intuitivement leur disjonction).
            \pause
        \item $X\orth{}, X$ $\; \sim \; \neg X \lor X$. \\
        \pause $\rightarrow$ C'est une tautologie!
            \pause
        \item $(A \parr B\orth{}) \tensor C, D$ $\; \sim \; ((A \lor \neg B) \land C) \lor D$.
    \end{itemize}
\end{frame}

\begin{frame}{Preuves en calcul des séquents linéaire}
    \begin{itemize}
        \item L'ensemble des preuves \proofs{} est défini par les règles d'induction suivantes:
            \begin{equation*}
            \begin{prooftree}
              \axv{X\orth, X}
            \end{prooftree}
            \; \; \;
            \begin{prooftree}
              \hypv{\sequent}
              \permv{\someperm}{\permapp{\someperm}{\sequent}}
            \end{prooftree}
            \; \; \;
            \begin{prooftree}
              \hypv{\sequent, A, B, \sequentbis}
              \parrv{\sequent, A \parr B, \sequentbis}
            \end{prooftree}
            \; \; \;
            \begin{prooftree}
              \hypv{\sequent, A}
              \hypv{B, \sequentbis}
              \tensorv{\sequent, A \tensor B, \sequentbis}
            \end{prooftree}
            \end{equation*}
            \pause
        \item Règle $\mathit{ax}$
            \pause
        \item Règle $\textit{ex}_{\someperm}$: les séquents sont des \textit{multi-ensembles} (où l'on distingue les occurences), réalisés par des \textit{listes}.
            \pause
        \item Règle $\parr$
            \pause
        \item Règle $\tensor$: introduit la notion de coût sur les hypothèses.\\
        Prouver $A \tensor B$ revient à prouver $A$ et $B$. Pour prouver $A \tensor B$ à partir d'un ensemble d'hypothèses $\Sigma$, on doit en choisir une partition $\sequent, \sequentbis$, et prouver $A$ avec toutes les hypothèses de $\sequent$, et $B$ avec toutes celles de $\sequentbis$.
    \end{itemize}
\end{frame}

\begin{frame}{Exemple: une preuve où l'on choisit la partition}
    \begin{itemize}
        \item Règles: 
            \begin{equation*}
            \begin{prooftree}
              \axv{X\orth, X}
            \end{prooftree}
            \; \; \;
            \begin{prooftree}
              \hypv{\sequent}
              \permv{\someperm}{\permapp{\someperm}{\sequent}}
            \end{prooftree}
            \; \; \;
            \begin{prooftree}
              \hypv{\sequent, A, B, \sequentbis}
              \parrv{\sequent, A \parr B, \sequentbis}
            \end{prooftree}
            \; \; \;
            \begin{prooftree}
              \hypv{\sequent, A}
              \hypv{B, \sequentbis}
              \tensorv{\sequent, A \tensor B, \sequentbis}
            \end{prooftree}
            \end{equation*}
        \item On partitionne $\Sigma = \{{X_1}\orth, {X_2}\orth\}$:
        \begin{equation*}
        \begin{prooftree}
            \axv{{X_1}\orth, X_1}
            \axv{{X_2}\orth, X_2}
            \permv{(2, 1)}{X_2, {X_2}\orth}
            \tensorv{{X_1}\orth, X_1 \tensor X_2, {X_2}\orth}
            \permv{(3, 2, 1)}{{X_2}\orth, X_1 \tensor X_2, {X_1}\orth}
        \end{prooftree}
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}{La structure des preuves est redondante}
    \begin{itemize}
        \item L'information nécessaire est en rouge et bleu:
            \begin{equation*}
            \begin{prooftree}
                \hypv{X_1, {X_1}\orth, X_2, {X_2}\orth}
                {\infer{1}[{\ensuremath{\parr}}]{\vdash \textcolor{red}{X_1, {X_1}\orth} \textcolor{blue}{\parr} \textcolor{red}{X_2, {X_2}\orth}}}
            \end{prooftree}
            \end{equation*}
            \pause
        \item En fait, les permutations ne sont jamais nécessaires (en ayant une notion d'occurrence):
            \begin{equation*}
                \begin{prooftree}
                    \axv{\foblig{{X_1}\orth, X_1}}
                    \axv{\foblig{{X_2}\orth, X_2}}
                    \permv{(2, 1)}{X_2, {X_2}\orth}
                    {\infer{2}[{\ensuremath{\tensor}}]{{X_1}\orth, X_1 \mathbin{\textcolor{blue}{\tensor}} X_2, {X_2}\orth}}
                    \permv{(3, 2, 1)}{\foblig{{X_2}\orth, X_1 \textcolor{blue}{\tensor} X_2, {X_1}\orth}}
                \end{prooftree}
            \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}{Cette redondance se retrouve dans Click \& Collect}
    Démonstration: preuve du séquent $X_5, X_4, {X_1}\orth \tensor ({X_2}\orth \tensor ({X_3}\orth \tensor ({X_4}\orth \tensor {X_5}\orth))), X_1, X_3 \parr X_2$.
\end{frame}

\begin{frame}{Notre solution}
    \begin{itemize}
        \item Manipuler en arrière-plan des représentations non-redondantes, équivalentes aux preuves.
        \item Utiliser des heuristiques d'autocomplétion et de détection d'erreurs.
     \end{itemize}
\end{frame}

\begin{frame}{Représentations}
    Couple $(t, \sequent)$, où $t$ est un arbre encodant le squelette de la preuve, et $\sequent$ est le séquent prouvé.
    \begin{equation*}
    \begin{prooftree}
        \axv{\textcolor{red}{{X_1}\orth, X_1}}
        \axv{\textcolor{Aquamarine}{{X_2}\orth}, \textcolor{Aquamarine}{X_2}}
        \permv{(2, 1)}{\textcolor{Aquamarine}{X_2}, \textcolor{Aquamarine}{{X_2}\orth}}
        \tensorv{\textcolor{red}{{X_1}\orth}, \textcolor{red}{X_1} \textcolor{green}{\tensor} \textcolor{Aquamarine}{X_2}, \textcolor{Aquamarine}{{X_2}\orth}}
        \parrv{\textcolor{red}{\textcolor{red}{{X_1}\orth}} \textcolor{blue}{\parr} (\textcolor{red}{X_1} \textcolor{green}{\tensor} \textcolor{Aquamarine}{X_2}), \textcolor{Aquamarine}{{X_2}\orth}}
    \end{prooftree}
    \end{equation*}\\
    \begin{equation*}
    \begin{tikzpicture}%
        [level 2/.style={sibling distance=3.5cm}]
        \node {$\textcolor{blue}{U_{1 \epsilon}}$}
        child {node {$\textcolor{green}{B_{1 \Right}}$}
            child {node {$\textcolor{red}{F_{1 \Left, \; 1 \Right \cdot \Left}}$}}
            child {node {$\textcolor{Aquamarine}{F_{1 \Right \cdot \Right, \; 2 \epsilon}}$}}
        };
    \end{tikzpicture}\vdash \textcolor{red}{{X_1}\orth} \textcolor{blue}{\parr} (\textcolor{red}{X_1} \textcolor{green}{\tensor} \textcolor{Aquamarine}{X_2}), \textcolor{Aquamarine}{{X_2}\orth}
    \end{equation*}
\end{frame}

\begin{frame}{Représentations}
    \begin{itemize}
        \item Les représentations correctes sont équivalentes aux preuves: il existe des fonctions d'encodage et de décodage telles que:
            \begin{itemize}
                \item L'encodage est injectif \textit{à permutations intermédiaires près}.
                \item Le décodage est injectif.
            \end{itemize}
    \end{itemize}
\end{frame}

%% ajouter théorèmes d'équivalence

\begin{frame}{Représentations partielles}
    \begin{itemize}
        \item On étend nos représentations à des représentations partielles.
            \pause
        \item Elles ont des ``trous'', correspondant aux endroits de la preuve qu'on ne connaît pas encore.
            \pause
        \item Une représentation partielle correspond à une preuve partielle, où l'on peut calculer des occurrences possibles et obligatoires.
            \pause
        \item Exemple:
            \begin{equation*}
                \begin{tikzpicture}%
                    [level 2/.style={sibling distance=3.5cm}]
                    \node {$\textcolor{orange}{U_{3 \epsilon}}$}
                    child {node {$\textcolor{green}{B_{1 \epsilon}}$}
                        child {node {$\unknown$}}
                        child {node {$\unknown$}}
                    };
                \end{tikzpicture}
                \vdash X_1 \textcolor{green}{\tensor} X_2\orth, X_2\tensor X_3\orth, X_1\orth \textcolor{orange}{\parr} X_3
            \end{equation*}
            \begin{prooftree*}
                  \hypv{X_1, \textcolor{gray}{X_2\tensor X_3\orth}, \textcolor{gray}{X_1\orth}, \textcolor{gray}{X_3}}
                  \hypv{X_2\orth, \textcolor{gray}{X_2\tensor X_3\orth}, \textcolor{gray}{X_1\orth}, \textcolor{gray}{X_3}}
               \tensorv{X_1 \textcolor{green}{\tensor} X_2\orth, X_2\tensor X_3\orth, X_1\orth, X_3}
            \parrv{X_1 \textcolor{green}{\tensor} X_2\orth, X_2\tensor X_3\orth, X_1\orth \textcolor{orange}{\parr} X_3}
            \end{prooftree*}
    \end{itemize}
\end{frame}

\begin{frame}{Principe général de l'assistant}
    \begin{itemize}
        \item L'utilisateur donne un séquent $\sequent$ à prouver, et part de la représentation partielle minimale $(\unknown, \sequent)$.
            \pause
        \item Guidé par l'assisant, il colmate étape par étape les trous, en les remplaçant par des informations sur la preuve.
            \pause
        \item S'il aboutit à une représentation complète, elle est décodée et la preuve est affichée.
    \end{itemize}
\end{frame}

\begin{frame}{Un exemple d'exécution : preuve de ${X_1}\orth \parr (X_1 \tensor X_2), {X_2}\orth$}
    \begin{equation*}
    \unknown 
    \end{equation*}
    \begin{equation*}
        \begin{prooftree}
            \hypv{{X_1}\orth \parr (X_1 \tensor X_2), {X_2}\orth}
        \end{prooftree}
    \end{equation*}
\end{frame}

\begin{frame}{Un exemple d'exécution}
    \begin{equation*}
    \begin{tikzpicture}%
        [level 2/.style={sibling distance=3.5cm}]
        \node {$\textcolor{blue}{U_{1 \epsilon}}$}
        child {node {$\unknown$}
        };
    \end{tikzpicture}
    \end{equation*}
    \begin{equation*}
        \begin{prooftree}
               \hypv{{X_1}\orth, X_1 \tensor X_2, {X_2}\orth}
            \parrv{{X_1}\orth \textcolor{blue}{\parr} (X_1 \tensor X_2), {X_2}\orth}
        \end{prooftree}
    \end{equation*}
\end{frame}

\begin{frame}{Un exemple d'exécution}
    \begin{equation*}
    \begin{tikzpicture}%
        [level 2/.style={sibling distance=1.5cm}]
        \node {$\textcolor{blue}{U_{1 \epsilon}}$}
        child {node {$\textcolor{green}{B_{1 \Right}}$}
            child {node {$\unknown$}}
            child {node {$\unknown$}}
        };
    \end{tikzpicture}
    \end{equation*}
    \begin{equation*}
        \begin{prooftree}
                  \hypv{\textcolor{gray}{{X_1}\orth}, X_1, \textcolor{gray}{{X_2}\orth}}
                  
                  \hypv{\textcolor{gray}{{X_1}\orth}, X_2, \textcolor{gray}{{X_2}\orth}}
               \tensorv{{X_1}\orth, X_1 \textcolor{green}{\tensor} X_2, {X_2}\orth}
            \parrv{{X_1}\orth \textcolor{blue}{\parr} (X_1 \textcolor{green}{\tensor} X_2), {X_2}\orth}
        \end{prooftree}
    \end{equation*}
\end{frame}

\begin{frame}{Un exemple d'exécution}
    \begin{equation*}
    \begin{tikzpicture}%
        [level 2/.style={sibling distance=1.5cm}]
        \node {$\textcolor{blue}{U_{1 \epsilon}}$}
        child {node {$\textcolor{green}{B_{1 \Right}}$}
            child {node {$\textcolor{red}{F_{1 \Left, \; 1 \Right \cdot \Left}}$}}
            child {node {$\unknown$}}
        };
    \end{tikzpicture}
    \end{equation*}
    \begin{equation*}
        \begin{prooftree}
                  \axv{\textcolor{red}{{X_1}\orth, X_1}}
            
                  \hypv{X_2, {X_2}\orth}
               \tensorv{\textcolor{red}{{X_1}\orth}, \textcolor{red}{X_1} \textcolor{green}{\tensor} X_2, {X_2}\orth}
            \parrv{\textcolor{red}{{X_1}\orth} \textcolor{blue}{\parr} (\textcolor{red}{X_1} \textcolor{green}{\tensor} X_2), {X_2}\orth}
        \end{prooftree}
    \end{equation*}
\end{frame}

\begin{frame}{Un exemple d'exécution}
    \begin{equation*}
    \begin{tikzpicture}%
        [level 2/.style={sibling distance=1.5cm}]
        \node {$\textcolor{blue}{U_{1 \epsilon}}$}
        child {node {$\textcolor{green}{B_{1 \Right}}$}
            child {node {$\textcolor{red}{F_{1 \Left, \; 1 \Right \cdot \Left}}$}}
            child {node {$\textcolor{Aquamarine}{F_{1 \Right \cdot \Right, \; 2 \epsilon}}$}}
        };
    \end{tikzpicture}
    \end{equation*}
    \begin{equation*}
        \begin{prooftree}
            \axv{\textcolor{red}{{X_1}\orth, X_1}}
            \axv{\textcolor{Aquamarine}{{X_2}\orth}, \textcolor{Aquamarine}{X_2}}
            \permv{(2, 1)}{\textcolor{Aquamarine}{X_2}, \textcolor{Aquamarine}{{X_2}\orth}}
            \tensorv{\textcolor{red}{{X_1}\orth}, \textcolor{red}{X_1} \textcolor{green}{\tensor} \textcolor{Aquamarine}{X_2}, \textcolor{Aquamarine}{{X_2}\orth}}
            \parrv{\textcolor{red}{\textcolor{red}{{X_1}\orth}} \textcolor{blue}{\parr} (\textcolor{red}{X_1} \textcolor{green}{\tensor} \textcolor{Aquamarine}{X_2}), \textcolor{Aquamarine}{{X_2}\orth}}
        \end{prooftree}
    \end{equation*}
\end{frame}

\begin{frame}{Fiabilité de l'assistant}
    \begin{itemize}
        \item Correction: si l'utilisateur aboutit, le guidage de notre assistant assure que la preuve construite est correcte.
        \item Complétude: à permutations intermédiaires près, il est possible de construire n'importe quelle preuve grâce à notre assistant.
            \pause
        \item Les heuristiques d'autocomplétion et de détection d'erreurs sont correctes, et ne retirent pas d'expressivité à l'utilisateur.
    \end{itemize}
\end{frame}

\begin{frame}{Démonstration de mll\_prover}
    Prouvons le même exemple qu'avec Click \& Collect: $X_5, X_4, {X_1}\orth \tensor ({X_2}\orth \tensor ({X_3}\orth \tensor ({X_4}\orth \tensor {X_5}\orth))), X_1, X_3 \parr X_2$.
\end{frame}

\begin{frame}{Conclusion}
    \begin{itemize}
        \item mll\_prover est plus efficace que Click \& Collect pour les utilisateurs experts.
            \pause
        \item Pistes d'améliorations:
            \begin{itemize}
                \item Ajouter une interface graphique.
                \item Revenir en arrière dans les choix.
                \item Enrichir les heuristiques d'autocomplétion.
                \item Étendre l'assistant à LL.
            \end{itemize}
    \end{itemize}
\end{frame}

\end{document}